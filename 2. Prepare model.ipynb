{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model based on VGG-16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=[BS,3,H,W]\n",
    "# output=[BS,7,H,W]\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](files/fig_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まずはVGG-16のパスを作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文中の実装ではVGG16のフィルタ数はステージ毎に32,64,128,256,512となっているが、\n",
    "これはpytorchでは一般的な実装ではない。\n",
    "\n",
    "torchvisionに用意されているVGG16モデルに従って実装を行う場合と論文のVGG16構造の２種類を用意する。\n",
    "（VGG16のフィルタ数はステージ毎に64,128,256,512,512）\n",
    "torchvisionのほうが計算コストは増えるが、pretrain weightsを使用できるため精度は向上すると考える。\n",
    "\n",
    "参考repoもpytorch VGG16に則った実装をしていた。\n",
    "https://github.com/princewang1994/TextSnake.pytorch/blob/b4ee996d5a4d214ed825350d6b307dd1c31faa07/network/vgg.py#L77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文実装のVGG16構造\n",
    "def Paper_VGG16():\n",
    "    layers = []\n",
    "    in_channels = 3    \n",
    "    # VGGのモデル構造を記入\n",
    "    cfg = [32, 32, \"M\", 64, 64, \"M\", 128, 128, 128, \"MC\", 256, 256, 256, \"M\", 512, 512, 512, \"M\"]    \n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == \"MC\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)] #メモリ節約\n",
    "            in_channels = v\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "# FPN用に各Maxpooling後の出力を取り出せるようなBackboneに変更\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, pretrain=True, original=False):\n",
    "        super().__init__()        \n",
    "        if not original:\n",
    "            # Torchvisionモデルを使用        \n",
    "            basemodel = torchvision.models.vgg16(pretrained=pretrain)\n",
    "            # 各ステージを実装\n",
    "            self.stage1 = nn.Sequential(*[basemodel.features[layer] for layer in range(0, 5)])\n",
    "            self.stage2 = nn.Sequential(*[basemodel.features[layer] for layer in range(5, 10)])\n",
    "            self.stage3 = nn.Sequential(*[basemodel.features[layer] for layer in range(10, 17)])\n",
    "            self.stage4 = nn.Sequential(*[basemodel.features[layer] for layer in range(17, 24)])\n",
    "            self.stage5 = nn.Sequential(*[basemodel.features[layer] for layer in range(24, 31)])\n",
    "        elif original:\n",
    "            # 論文VGG16を使用\n",
    "            basemodel = Paper_VGG16()\n",
    "            self.stage1 = nn.Sequential(*[basemodel[layer] for layer in range(0, 5)])\n",
    "            self.stage2 = nn.Sequential(*[basemodel[layer] for layer in range(5, 10)])\n",
    "            self.stage3 = nn.Sequential(*[basemodel[layer] for layer in range(10, 17)])\n",
    "            self.stage4 = nn.Sequential(*[basemodel[layer] for layer in range(17, 24)])\n",
    "            self.stage5 = nn.Sequential(*[basemodel[layer] for layer in range(24, 31)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.stage1(x)\n",
    "        C2 = self.stage2(C1)\n",
    "        C3 = self.stage3(C2)\n",
    "        C4 = self.stage4(C3)\n",
    "        C5 = self.stage5(C4)\n",
    "        return C1,C2,C3,C4,C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50(nn.Module):\n",
    "    def __init__(self, pretrain=True):\n",
    "        super().__init__()        \n",
    "        # Torchvisionモデルを使用        \n",
    "        basemodel = torchvision.models.resnet50(pretrain)\n",
    "        self.stage1 = nn.Sequential(*list(basemodel.children())[0:3])\n",
    "        self.stage2 = nn.Sequential(*list(basemodel.children())[3:5])\n",
    "        self.stage3 = nn.Sequential(*list(basemodel.children())[5:6])\n",
    "        self.stage4 = nn.Sequential(*list(basemodel.children())[6:7])\n",
    "        self.stage5 = nn.Sequential(*list(basemodel.children())[7:8])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.stage1(x)\n",
    "        C2 = self.stage2(C1)\n",
    "        C3 = self.stage3(C2)\n",
    "        C4 = self.stage4(C3)\n",
    "        C5 = self.stage5(C4)\n",
    "        return C1,C2,C3,C4,C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 256, 128, 128])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 1024, 32, 32])\n",
      "torch.Size([1, 2048, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# ダミー画像を入力しVGG出力をテスト\n",
    "model = Resnet50(pretrain=True)\n",
    "inputs = torch.randn(1,3,512,512)\n",
    "outputs = model(inputs)\n",
    "print(outputs[0].size())\n",
    "print(outputs[1].size())\n",
    "print(outputs[2].size())\n",
    "print(outputs[3].size())\n",
    "print(outputs[4].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 次にUpsampleクラスとTextNetを作成する.\n",
    "Upsampleクラスでは収束性が悪かったため、batchnormをあわせたUpsample_BNクラスも作成した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文にあるupsampleパスを実装\n",
    "# Conv1x1 -> Conv3x3 -> Deconv2x\n",
    "# https://github.com/princewang1994/TextSnake.pytorch/blob/master/network/textnet.py\n",
    "# deconvのカーネルサイズは論文中には書いてない。\n",
    "# TODO:元論文では他論文との比較のため、BatchNormが入っていないので学習が不安定になる。\n",
    "# 精度向上のためにはBatchNormを加えたほうが良い。\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, upsampled, shortcut):\n",
    "        # ショートカットした特徴量とアップサンプルされた特徴量を足し合わせる\n",
    "        x = torch.cat([upsampled, shortcut], dim=1)\n",
    "        x = self.conv1x1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3x3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv(x)\n",
    "        # アップサンプルパスを出力\n",
    "        return x\n",
    "    \n",
    "# Upsample with batchnorm\n",
    "class Upsample_BN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.deconv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, upsampled, shortcut):\n",
    "        # ショートカットした特徴量とアップサンプルされた特徴量を足し合わせる\n",
    "        x = torch.cat([upsampled, shortcut], dim=1)\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3x3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv(x)\n",
    "        # アップサンプルパスを出力\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make U-Net like FCN\n",
    "class TextNet(nn.Module):\n",
    "    def __init__(self, output_channel=7, pretrain=True, backbone=\"VGG16\", original=False):\n",
    "        super().__init__()\n",
    "        self.output_channel = output_channel\n",
    "        \n",
    "        # 論文通り VGG16のみ実装する\n",
    "        if backbone == \"VGG16\":\n",
    "            self.basemodel = VGG16(pretrain=pretrain, original=original)\n",
    "        elif backbone == \"resnet50\":\n",
    "            self.basemodel = Resnet50(pretrain=pretrain)\n",
    "        else:\n",
    "            raise NotImplementedError(backbone)\n",
    "        \n",
    "        # TODO: 単なるUNETのアップサンプルパス。これをFPNに変えると精度向上する可能性あり。\n",
    "        # Channel数の詳細な指定は論文になかったので経験に即した値に変更\n",
    "        \n",
    "        # ベースチャネル数を論文実装か否かで切り替える\n",
    "        if original:\n",
    "            base_channels = 16\n",
    "        else:\n",
    "            base_channels = 32        \n",
    "        if backbone == \"VGG16\":\n",
    "            # C5の出力のアップサンプルパス\n",
    "            self.deconv5 = nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1)\n",
    "            # C4出力のアップサンプルパス\n",
    "            self.merge4 = Upsample(512+base_channels*16, 256)\n",
    "            # C3出力のアップサンプルパス\n",
    "            self.merge3 = Upsample(256+base_channels*8, 128)\n",
    "            # C2出力のアップサンプルパス\n",
    "            self.merge2 = Upsample(128+base_channels*4, 64)\n",
    "            # C1出力のアップサンプルパス\n",
    "            self.merge1 = Upsample(64+base_channels*2, base_channels)\n",
    "        else:\n",
    "            # C5の出力のアップサンプルパス\n",
    "            self.deconv5 = nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=2, padding=1)\n",
    "            # C4出力のアップサンプルパス\n",
    "            self.merge4 = Upsample_BN(1024+1024, 512)\n",
    "            # C3出力のアップサンプルパス\n",
    "            self.merge3 = Upsample_BN(512+512, 256)\n",
    "            # C2出力のアップサンプルパス\n",
    "            self.merge2 = Upsample_BN(256+256, 64)\n",
    "            # C1出力のアップサンプルパス\n",
    "            self.merge1 = Upsample_BN(64+64, base_channels)\n",
    "            \n",
    "        # C1出力のアップサンプルおよび出力\n",
    "        self.predict = nn.Sequential(\n",
    "                nn.Conv2d(base_channels, base_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(base_channels, self.output_channel, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        C1,C2,C3,C4,C5 = self.basemodel(x)\n",
    "        #upsample deconv5\n",
    "        U5 = self.deconv5(C5)\n",
    "        # merge and upsample C4\n",
    "        U4 = self.merge4(U5, C4)\n",
    "        # merge and upsample C3\n",
    "        U3 = self.merge3(U4, C3)\n",
    "        # merge and upsample C2\n",
    "        U2 = self.merge2(U3, C2)\n",
    "        # merge and upsample C1\n",
    "        U1 = self.merge1(U2, C1)\n",
    "        # Output predictions\n",
    "        out = self.predict(U1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Test TextNet outputs\n",
    "model = TextNet(backbone=\"resnet50\")\n",
    "inputs = torch.rand(2,3,512,512)\n",
    "print(model(inputs).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextNet(\n",
      "  (basemodel): Resnet50(\n",
      "    (stage1): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage4): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage5): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv5): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (merge4): Upsample_BN(\n",
      "    (conv1x1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x3): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (merge3): Upsample_BN(\n",
      "    (conv1x1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x3): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (merge2): Upsample_BN(\n",
      "    (conv1x1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x3): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (merge1): Upsample_BN(\n",
      "    (conv1x1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconv): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (predict): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(32, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
